시작 코드 세부 정보
초기 성능 : 변경되지 않은 projSceneRecBoW.m을 실행하면 모든 테스트 이미지의 범주가 임의로 추측됩니다. 이것은 15 개의 클래스로 우연히 ~ 15 %의 정확도에서 ~ 1 %의 정확도를 달성합니다.

데이터 : 시작 코드는 각 카테고리의 총 100 개 이미지 (총 1500 회의 교육 사례 및 총 1500 개의 테스트 사례)에 대한 교육과 테스트를 수행합니다. 실제 연구 논문에서는 데이터의 무작위 분할에 대한 성능을 교육 및 테스트 세트로 테스트 할 것으로 예상되지만 디버깅을 쉽게하기 위해 시작 코드는이를 수행하지 않습니다.

평가 및 시각화 : 초보자 용 코드 함수 create_results_webpage.m은 혼란 행렬을 만들고 projSceneRecBoW.m을 실행할 때마다 웹 페이지로 진실한 긍정 표, 거짓 긍정 및 false negative 표를 생성하여 분류 결정을 시각화합니다.

쓰기
프로세스 및 알고리즘을 설명하고, 결과를 보여주고, 추가 크레딧을 설명하고, 관련성이 있다고 생각되는 다른 정보를 알려주십시오. 우리는 LaTeX 템플릿 writeup / writeup.tex를 제공합니다. PDF로 컴파일하여 코드와 함께 제출하십시오.

태스크:

작은 이미지 + 가장 가까운 이웃, 가장 가까운 이웃의 가방, 가장 가까운 이웃의 SVM, 모든 선형 SVM 대 단어 + 1의 가방 등 세 가지 인식 파이프 라인에 대한 분류 성능을보고하십시오.
최상의 인식 설정을 위해서는 초보자 용 코드 results_webpage / index.html에 의해 생성 된 전체 혼용 행렬 및 분류 자 ??결과 테이블을 포함하십시오. 제출 스크립트에는이 html 파일이 포함됩니다.
우리는 익명 TA 등급을 매길 수 있으므로 귀하의 이름이나 ID를 귀하의 글이나 코드에 포함하지 마십시오.

표제
+05 점 : 장면 인식을위한 작은 이미지 기능을 만듭니다. (get_tiny_images.m)
+10 점 : 가장 가까운 이웃 분류 자. (nn_classify.m)
+20 점 : 임의의 일련의 학습 기능으로 어휘력을 구축하십시오. (build_vocabulary.m)
+20 점 : 이미지 훈련 및 시험을위한 시각적 단어의 히스토그램을 작성하십시오. (get_bags_of_words.m)
+20 점 : 1 단어 대 가방의 모든 SVM을 훈련하십시오. (svm_classify.m)
+05 pts : 설계 결정 및 평가에 대한 의견.
+10 점 : 추가 크레딧 (최대 10 점)
-5 * n pts : 핸드 포멧의 지시 사항을 따르지 않을 때마다 5 점을 잃습니다.
추가 학점
모든 추가 크레딧을 위해 구현 한 특정 방법의 영향을 보여주는 정량 분석을 포함하십시오. 사소한 구현은 완전한 추가 크레딧을받을 가치가 없을 수도 있기 때문에 각 항목은 "최대"의 포인트입니다. 추가 신용의 대부분은 기본 작은 이미지 및 가장 가까운 이웃 방법이 아니라 프로젝트의 단어 + SVM 파이프 라인의 최종 백에 초점을 둡니다.

피쳐 표현 추가 크레딧 :

최대 5 점 : 추가 기능 (예 : GIST 설명자 및 자체 유사성 설명자)을 추가하고 분류 프로그램에서 모두 고려할 수 있습니다.
기능 양자화 및 단어 여분 가방 :

최대 5 점 : "소프트 할당"을 사용하여 시각적 단어를 히스토그램 빈에 할당합니다. 각각의 시각적 단어는 거리 가중 투표를 여러 빈에 던집니다. 이것은 Chatfield 외의 "커널 코드북 인코딩"이라고합니다.
분류 자 추가 신용 :

최대 5 점 : Boiman, Schechtman 및 Irani의 CVPR 2008 방법을 사용하여 가장 가까운 이웃 분류 기준을 경쟁 SVPM보다 우수하거나 개선 할 수 있도록 시도하십시오.
공간 피라미드 표현 및 분류 :

최대 5 점 : Lazebnik 외 2006에 설명 된 공간 피라미드 피쳐 표현을 구현하여 피처에 공간 정보를 추가합니다.

Potentially useful: MATLAB functions: extractHOGFeatures() and others, kmeans(), fitclinear(), fitcsvm(), predict(), pdist2().

Forbidden functions: bagOfFeatures(), evaluateImageRetrieval(), etc.

노트
Lazebnik et al. 2006 년은 읽을만한 훌륭한 논문이지만, 우리가 논의하는 기본 방법 (제로 레벨 피라미드에 해당)이 아니라 정교한 공간 피라미드 (여분의 크레디트가 아닌)를 구현할 것입니다. bag of words 모델에 대한 현대적인 기능 인코딩 방법에 대한 훌륭한 설문 조사는 Chatfield et al.을 참조하십시오. 2011 년

작은 이미지와 가장 가까운 이웃 분류
작은 이미지 표현과 가장 가까운 이웃 분류자를 구현함으로써 시작하십시오. 그들은 이해하기 쉽고, 구현하기 쉽고, 실험 설정 (10 초 미만)을 위해 매우 빠르게 실행됩니다. Torralba 등의 작은 이미지 기능은 가능한 가장 단순한 이미지 표현 중 하나입니다. 하나는 각 이미지를 작은 고정 해상도 (16x16 권장)로 간단히 조정합니다. 작은 이미지의 평균 길이가 0이고 단위 길이가 0 인 경우 조금 더 잘 작동합니다. 이것은 고주파 이미지 컨텐츠를 모두 버리고 특히 공간 또는 밝기 이동에 불변하지 않기 때문에 특히 좋은 표현은 아닙니다. Torralba et al. 후자의 단점을 줄이기 위해 여러 가지 정렬 방법을 제안하지만이 프로젝트의 정렬에 대해서는 걱정하지 않을 것입니다. 우리는보다 정교한 표현을 비교할 수있는 성능의 기준으로 작은 이미지를 사용하고 있습니다. 자세한 내용은 get_tiny_images.m을 참조하십시오.

가장 가까운 이웃 분류 자도 똑같이 이해하기 쉽습니다. 테스트 피쳐를 특정 카테고리로 분류 할 때 "가장 가까운"트레이닝 예제 (L2 거리가 충분한 메트릭)를 찾아 가장 가까운 트레이닝 예제의 레이블을 테스트 케이스에 할당합니다. 가장 가까운 이웃 분류자는 많은 바람직한 특징을 가지고있다 : 그것은 훈련을 필요로하지 않고, 임의로 복잡한 결정 경계를 나타낼 수 있고, 다원적 문제를 사소하게 지원한다. 그러나 훈련 소음에 취약합니다. 이는 K 개의 가장 가까운 이웃에 기반하여 투표함으로써 완화 될 수 있습니다 (그러나 그렇게 할 필요는 없습니다). 가장 가까운 이웃 분류 프로그램은 또한 특징 분류 기준이 증가함에 따라 영향을받습니다. 왜냐하면 분류 기준에는 어떤 차원이 관련 결정과 관련이 없는지를 알 수 없기 때문입니다. 자세한 내용은 nearest_neighbor_classify.m을 참조하십시오.

작은 이미지 표현과 가장 가까운 이웃 분류자를 함께 사용하면 15 장면 데이터베이스에서 15-25 %의 정확도를 얻을 수 있습니다. 비교를 위해 기회 성과는 ~ 7 %입니다.

단어 가방
단어 모델 가방은 자연어 처리에 사용되는 모델에서 영감을 얻어 이미지 분류에 널리 사용되는 기술입니다. 모델은 단어 배열 (이미지의 공간 정보)을 무시하거나 무시하며 시각적 단어의 빈도의 막대 그래프를 기반으로 분류합니다. "어휘"라는 시각적 단어는 로컬 기능의 큰 코퍼스를 클러스터링하여 설정됩니다. 양자화 된 피처가있는 범주 인식에 대한 자세한 내용은 Szeliski 14.4.1 장을 참조하십시오. 또한 14.3.2에서는 어휘 작성에 대해 설명하고 14.1에서는 분류 기술에 대해 다룹니다.

베이스 라인 장면 인식 파이프 라인을 구현 한 후에는 더 정교한 이미지 표현 인 quantized feature descriptors의 가방으로 넘어갈 것입니다. 교육 및 테스트 이미지를 피처 설명자로 표현하기 전에 먼저 시각적 단어의 어휘를 만들어야합니다.이 어휘는 우리의 교육 데이터베이스에있는 이미지에서 유사한 지역을 나타냅니다. 우리는 k-로 클러스터링하여이 어휘를 구성 할 것이고, 우리의 훈련 세트에서 수천 개의 로컬 특징 벡터를 의미합니다.

참고 : 이것은 k- 최근 인접 피처 기술자를 찾는 것과 동일하지 않습니다! 예를 들어, 훈련 데이터베이스가 주어지면 로컬 특징 벡터를 k = 50 클러스터로 클러스터링하는 것으로 시작할 수 있습니다. 이러한 클러스터의 중심은 시각적 단어 어휘입니다. 우리가 관찰 한 새로운 특징 점에 대해 우리는 시각적 단어를 가장 가까운 클러스터에서 찾을 수 있습니다. 샘플링 속도가 느리고 많은 로컬 기능을 클러스터링 할 수 있기 때문에 시작 코드는 클러스터 중심을 저장하고 이후 실행시이를 다시 계산하는 것을 방지합니다. 다른 매개 변수로 다시 실행하는 경우이 점에주의하십시오. 자세한 내용은 build_vocabulary.m을 참조하십시오.

이제 우리는 훈련을 표현하고 시각적 단어의 히스토그램으로 이미지를 테스트 할 준비가되었습니다. 각 이미지에 대해 많은 피처 설명자를 조밀하게 샘플링합니다. 수백 개의 특징 디스크립터를 저장하는 대신 시각적 단어 어휘로 얼마나 많은 특징 디스크립터가 각 클러스터에 속하는지 계산합니다. 이것은 모든 특징 디스크립터에 대한 가장 가까운 이웃 k- 평균 중심을 찾는 것에 의해 이루어진다. 따라서 우리가 50 개의 시각적 단어로 구성된 어휘를 가지고 있고 이미지에서 220 개의 특징을 발견하면 단어 표현의 가방은 50 개의 차원의 막대 그래프가되며 각 bin은 특성 설명자가 해당 클러스터에 할당 된 횟수를 계산하고 히스토그램은 이미지 크기가 피처 크기의 백을 크게 변경시키지 않도록 표준화되어야합니다. 자세한 내용은 get_bags_of_words.m을 참조하십시오.

가장 가까운 이웃 분류 자와 쌍을 이루었을 때 단어 표현 가방이 얼마나 잘 작동하는지 측정해야합니다. 단어 표현의 백 (클러스터 수, 샘플링 밀도, 샘플링 스케일, 특성 설명자 매개 변수 등)에 대한 많은 설계 결정 및 무료 매개 변수가 있으므로 성능은 50 %에서 60 %까지 다양합니다.

다중 클래스 SVM
마지막 작업은 1 대 vs 모든 선형 SVM을 훈련하여 단어 기능 공간의 백을 분류하는 것입니다. 선형 분류기는 간단한 학습 모델입니다. 특징 공간은 학습 된 초평면으로 구분되며, 테스트 케이스는 해당 초평면의 어느면에 떨어 졌는지에 따라 분류됩니다. 이 모델이 가장 가까운 이웃 분류 자보다 표현력이 적음에도 불구하고 종종 더 잘 수행됩니다. 예를 들어, 어쩌면 단어 표현의 백에서 50 개의 시각적 단어 중 40 개는 정보가 없습니다. 그들은 단순히 이미지가 '숲'인지 '침실'인지에 대한 결정을 내리는 데 도움이되지 않습니다. 아마도 모든 종류의 장면에서 발생하는 부드러운 패치, 그라디언트 또는 스텝 가장자리를 나타낼 수 있습니다. 가장 가까운 이웃 분류 자로부터의 예측은 이러한 빈번한 시각적 단어의 영향을 많이받는 반면, 선형 분류자는 특징 벡터의 차원이 덜 관련되어 결정을 내릴 때 그 비중을 낮추는 것을 알 수 있습니다.

선형 분류기를 배우는 데는 여러 가지 방법이 있지만 지원 벡터 시스템을 사용하여 선형 결정 경계를 찾습니다. 지원 벡터 머신을 구현할 필요가 없습니다. 그러나 선형 분류기는 본질적으로 2 진수이며 우리는 15 가지 분류 문제를 가지고 있습니다. 테스트 사례가 속한 범주 15 개를 결정하려면 15 개의 2 진수 1 대 모든 SVM을 교육해야합니다. 1-vs-all은 각 분류자를 '숲'대 '숲이 아닌', '부엌'대 '비 주방'등을 인식하도록 훈련된다는 것을 의미합니다. 모든 15 개의 분류자는 각 테스트 케이스에서 평가되고 가장 자신있게 긍정적 인 "분류 기준 분류 자"가됩니다. E.G. 'kitchen'분류자가 -0.2 (여기서 0은 결정 경계에 있음)의 점수를 반환하고 '포리스트'분류기가 -0.3의 점수를 반환하고 다른 모든 분류기가 훨씬 더 부정적이면 테스트 사례는 분류 자 중 누구도 결정 경계의 긍정적 측면에 테스트 케이스를 두지 않더라도 부엌으로 분류됩니다. SVM을 배울 때 모델 정규화를 제어하는 ??매개 변수 'lambda'가 있습니다. 정확도는 람다에 매우 민감하므로 많은 값을 테스트해야합니다. 자세한 내용은 svm_classify.m을 참조하십시오.

이제 1-vs 모든 선형 SVM과 쌍을 이룬 단어 표현의 백을 평가할 수 있습니다. 정확도는 매개 변수에 따라 60 %에서 70 % 사이 여야합니다. 추가 신용 제안을 구현하면 더 잘 수행 할 수 있습니다.

계산 속도
피쳐 추출, 범용 사전 작성을위한 클러스터링 및 피쳐로부터 히스토그램 작성은 느려질 수 있습니다. 좋은 구현은 10 분 이내에 전체 파이프 라인을 실행할 수 있지만, 이는 정확성을 희생 시키거나 (예 : 시각적 단어의 어휘가 너무 작거나 샘플링 속도가 너무 낮다). 중간 결과를 저장하거나 파이프 라인의 한 부분을 미세 조정하려는 경우 Matlab의 코드 섹션 기능을 사용하십시오.